{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WeirdTargets Module\"\"\"\n",
    "##########################################\n",
    "#      Future Statement Definitions      #\n",
    "##########################################\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import generator_stop\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import absolute_import\n",
    "##########################################\n",
    "#        Python Standard Library         #\n",
    "##########################################\n",
    "import argparse\n",
    "import re \n",
    "import math\n",
    "import json \n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import struct\n",
    "import datetime\n",
    "import inspect\n",
    "import collections\n",
    "import multiprocess\n",
    "import multiprocessing\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "import requests\n",
    "##########################################\n",
    "#   3rd Party Data Loading & Analysis    #\n",
    "##########################################\n",
    "import ujson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from gzip import GzipFile\n",
    "from toolz import partition_all\n",
    "##########################################\n",
    "#      3rd Party Parallel Computing      #\n",
    "##########################################\n",
    "import pathos\n",
    "import psutil\n",
    "import dask.dataframe as dd\n",
    "import pathos.multiprocessing as pmp\n",
    "from dask.threaded import get as ddscheduler\n",
    "from opentargets import OpenTargetsClient\n",
    "##########################################\n",
    "#       Module Level Dunder Names        #\n",
    "##########################################\n",
    "__copyright__ = \"Copyrights Â© 2019 Aly shmahell.\"\n",
    "__credits__   = [\"Aly Shmahell\"]\n",
    "__version__   = \"0.1.1\"\n",
    "__maintainer__= \"Aly Shmahell\"\n",
    "__email__     = [\"aly.shmahell@gmail.com\"]\n",
    "__status__    = \"Alpha\"\n",
    "##########################################\n",
    "##########################################\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exception Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeirdTargetsException(Exception):\n",
    "    \"\"\"\n",
    "    Exception Class\n",
    "    \"\"\"\n",
    "    __module__ = Exception.__module__\n",
    "    def __init__(self, error):\n",
    "        try:\n",
    "            line = sys.exc_info()[-1].tb_lineno\n",
    "        except AttributeError:\n",
    "            line = inspect.currentframe().f_back.f_lineno\n",
    "        self.args = f\"{type(self).__name__} (line {line}): {error}\",\n",
    "        sys.exit(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeirdTargetsPrinter(object):\n",
    "  \n",
    "    def pretty(self, x):\n",
    "        return re.sub(r\"\\n\\s+\", \"\\n\", x)\n",
    "\n",
    "    def oneliner(self, x):\n",
    "        return re.sub(r\"\\n\\s*\", \" \", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Argument Parser Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeirdTargetsArgParse(WeirdTargetsPrinter):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.args = None\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self.args, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallTargetsArgParse(WeirdTargetsArgParse):\n",
    "\n",
    "    def __id_regex(self, id):\n",
    "        regex = re.compile(r'^EFO_|^ENSG')\n",
    "        if not regex.match(id):\n",
    "            raise WeirdTargetsException(self.oneliner(\"\"\"--id should\n",
    "                                                          start with: \n",
    "                                                          <EFO_> or \n",
    "                                                          <ENSG>\"\"\"))\n",
    "        return id\n",
    "    def __check_args_compatibility(self, type, id):\n",
    "        if not((re.match(r'EFO_.+\\sdisease', f\"{id} {type}\"))\n",
    "                or (re.match(r'ENSG.+\\starget', f\"{id} {type}\"))):\n",
    "            raise WeirdTargetsException(self.oneliner(f\"\"\"type: {type} \n",
    "                                                           and id: {id} \n",
    "                                                           are incompatible.\"\"\"))\n",
    "            \n",
    "    def __init__(self):\n",
    "        super(SmallTargetsArgParse, self).__init__()\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--type\",\n",
    "                            type=str,\n",
    "                            help=self.oneliner(\"\"\"specify \n",
    "                                                   a type to \n",
    "                                                   look for, \n",
    "                                                   a target or \n",
    "                                                   a disease.\"\"\"),\n",
    "                            required=True,\n",
    "                            choices=['disease', 'target'])\n",
    "        parser.add_argument(\"--id\",\n",
    "                            type=self.__id_regex,\n",
    "                            help=\"specify an id to look for.\",\n",
    "                            required=True)\n",
    "        self.args = parser.parse_args()\n",
    "        self.__check_args_compatibility(self.args.type,\n",
    "                                        self.args.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigTargetsArgParse(WeirdTargetsArgParse):\n",
    "    def __init__(self):\n",
    "        super(BigTargetsArgParse, self).__init__()\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(\"--filename\",\n",
    "                            type=str,\n",
    "                            help=self.oneliner(\"\"\"specify a\n",
    "                                                   file that \n",
    "                                                   holds a \n",
    "                                                   collection \n",
    "                                                   of json \n",
    "                                                   objects.\"\"\"),\n",
    "                            required=True)\n",
    "        parser.add_argument(\"--tmp_dir\",\n",
    "                            type=str,\n",
    "                            help=self.oneliner(\"\"\"specify a\n",
    "                                                   folder that \n",
    "                                                   will hold\n",
    "                                                   lazily extracted\n",
    "                                                   features.\"\"\"),\n",
    "                            required=True)\n",
    "        self.args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WeirdTagets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeirdTargets(WeirdTargetsPrinter):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.empty_string = \"\"\n",
    "        \n",
    "    def testParallelism(self):\n",
    "        print(\"Testing Parallelism:\")\n",
    "        print(f\"\\t No. of Cores Available: {pmp.cpu_count()}\")\n",
    "        with pmp.Pool(pmp.cpu_count()) as pool:\n",
    "            PIDS = pool.map(lambda _: f\"{os.getpid()}\", range(pmp.cpu_count()+1))\n",
    "            print(f\"\\t No. of Cores Utilized:  {np.unique(PIDS).size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Parallelism:\n",
      "\t No. of Cores Available: 8\n",
      "\t No. of Cores Utilized:  8\n"
     ]
    }
   ],
   "source": [
    "weird_targets = WeirdTargets()\n",
    "weird_targets.testParallelism()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SmallTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallTargets(WeirdTargets):\n",
    "\n",
    "    def __init__(self, type, id):\n",
    "        self.type         = type\n",
    "        self.id           = id\n",
    "        self.inputs       = None\n",
    "        self.outputs      = []\n",
    "        self.elapsed_time = None\n",
    "        super(SmallTargets, self).__init__()\n",
    "\n",
    "    def __call__(self):\n",
    "        if self.type == \"disease\":\n",
    "            try:\n",
    "                self.inputs = OpenTargetsClient().get_associations_for_disease(self.id)\n",
    "            except:\n",
    "                raise WeirdTargetsException(f\"Incorrect Disease ID: {self.id}\")\n",
    "        if self.type == \"target\":\n",
    "            try:\n",
    "                self.inputs = OpenTargetsClient().get_associations_for_target(self.id)\n",
    "            except:\n",
    "                raise WeirdTargetsException(f\"Incorrect Target ID: {self.id}\")\n",
    "        if not self.inputs:\n",
    "            raise WeirdTargetsException(self.oneliner(\"\"\"The query did not\n",
    "                                                          return any usefull\n",
    "                                                          information.\"\"\"))\n",
    "        self.elapsed_time = time.time()\n",
    "        with pmp.Pool(pmp.cpu_count()) as pool:\n",
    "            overalls           = pool.map(lambda entry: entry['association_score']['overall'], self.inputs)\n",
    "            squared_overalls   = pool.map(lambda overall: overall**2,                          overalls)\n",
    "            minimum            = min(overalls)\n",
    "            maximum            = max(overalls)\n",
    "            average            = sum(overalls)/len(self.inputs)\n",
    "            standard_deviation = np.sqrt(\n",
    "                sum(squared_overalls)/len(self.inputs) - average**2)\n",
    "            self.outputs = {\n",
    "                \"Maximum\"           : maximum,\n",
    "                \"Minimum\"           : minimum,\n",
    "                \"Average\"           : average,\n",
    "                \"Standard Deviation\": standard_deviation\n",
    "            }\n",
    "        self.elapsed_time = time.time() - self.elapsed_time\n",
    "\n",
    "    def __str__(self):\n",
    "        if not self.outputs:\n",
    "            raise WeirdTargetsException(self.oneliner(\"\"\"you need to call \n",
    "                                                          the SmallTargets \n",
    "                                                          object first.\"\"\"))\n",
    "        return self.pretty(f\"\"\"Number of Entries :       {len(self.inputs)}\\n\n",
    "                                Elapsed Time      :       {self.elapsed_time} sec\\n\n",
    "                                Maximum           :       {self.outputs['Maximum']}\\n\n",
    "                                Minumum           :       {self.outputs['Minimum']}\\n\n",
    "                                Average           :       {self.outputs['Average']}\\n\n",
    "                                Standard Deviation:       {self.outputs['Standard Deviation']}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aly/.local/lib/python3.6/site-packages/opentargets/conn.py:299: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  self.api_specs = yaml.load(self.swagger_yaml)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Entries :       1343\n",
      "Elapsed Time      :       2.2975881099700928 sec\n",
      "Maximum           :       1.0\n",
      "Minumum           :       0.004\n",
      "Average           :       0.28802892735518787\n",
      "Standard Deviation:       0.31332124396113537\n"
     ]
    }
   ],
   "source": [
    "small_targets = SmallTargets('target', 'ENSG00000157764')\n",
    "small_targets()\n",
    "print(small_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncr(n, r):\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "def downloader(url, filepath):\n",
    "    r = requests.get(url, stream=True)\n",
    "    total_size = int(r.headers.get('content-length', 0))\n",
    "    block_size = 1024**2\n",
    "    t=tqdm(total=total_size, unit='iB', unit_scale=True)\n",
    "    with open(filepath, 'wb') as f:\n",
    "        for data in r.iter_content(block_size):\n",
    "            t.update(len(data))\n",
    "            f.write(data)\n",
    "    t.close()\n",
    "    if total_size != 0 and t.n != total_size:\n",
    "        print(\"ERROR, something went wrong\")\n",
    "\n",
    "class BigTargets(WeirdTargets):\n",
    "\n",
    "    def __init__(self, rawdir, rawurl, keysdict, outdir, outfile, groupnames, resultdir, resultfile, save_association_cardinatily=False):\n",
    "        if not os.path.isdir(outdir):\n",
    "            os.mkdir(outdir, 755)\n",
    "        if not os.path.isdir(resultdir):\n",
    "            os.mkdir(resultdir, 755)\n",
    "        if not os.path.isdir(rawdir):\n",
    "            os.mkdir(rawdir, 755)\n",
    "        super(BigTargets, self).__init__()\n",
    "        self.rawdir         :\"rawdir\"    = rawdir\n",
    "        self.rawfile        :\"rawfile\"   = rawurl.split('/')[-1]\n",
    "        self.rawurl         :\"rawurl\"    = rawurl\n",
    "        self.infile         :\"infile\"    = os.path.join(self.rawdir, self.rawfile)\n",
    "        self.keysdict       :\"keysdict\"  = keysdict\n",
    "        self.outdir         :\"outdir\"    = outdir\n",
    "        self.outfile        :\"outfile\"   = outfile\n",
    "        self.groupnames     :\"groupnames\"= groupnames\n",
    "        self.resultdir      :\"resultdir\" = resultdir\n",
    "        self.resultfile     :\"resultfile\"= resultfile\n",
    "        self.save_association_cardinatily = save_association_cardinatily\n",
    "\n",
    "    def __download__(self):\n",
    "       downloader(self.rawurl, self.infile)\n",
    "\n",
    "    def __traverse__(self, parsed, keys):\n",
    "        if len(keys)>1:\n",
    "            return self.__traverse__(parsed[keys[0]], keys[1:])\n",
    "        return parsed[keys[0]]\n",
    "\n",
    "    def __parsejson__(self, pyObject, tqdmObject):\n",
    "        tqdmObject.update(1)\n",
    "        parsed = ujson.loads(pyObject)\n",
    "        obj = {\n",
    "            key: self.__traverse__(parsed, self.keysdict[key])\n",
    "            for key in self.keysdict.keys()\n",
    "        }\n",
    "        return obj\n",
    "\n",
    "    def __json2panda__(self, batch, tqdmObject):\n",
    "        parsedJSON = map(lambda b: self.__parsejson__(b, tqdmObject), batch)\n",
    "        df = pd.DataFrame.from_records(parsedJSON, \n",
    "                                       columns=[\"target\",\n",
    "                                                \"disease\",\n",
    "                                                \"score\"])\n",
    "        return df\n",
    "    def __peek__(self, iterable):\n",
    "        try:\n",
    "            first = next(iterable)\n",
    "        except StopIteration:\n",
    "            return None, None\n",
    "        return first, itertools.chain([first], iterable)\n",
    "\n",
    "    def __persist__(self):\n",
    "        with tqdm(desc=f\"Feature Extraction{self.empty_string:>18}\") as tqdmObject:\n",
    "            with GzipFile(self.infile) as f:\n",
    "                batches = partition_all(\n",
    "                    math.floor(psutil.virtual_memory()[1]/(1024**3))*int(2e+4), f\n",
    "                )\n",
    "                while True:\n",
    "                    df, frames = self.__peek__(\n",
    "                        map(\n",
    "                            lambda b: self.__json2panda__(b, tqdmObject), batches\n",
    "                        )\n",
    "                    )\n",
    "                    if frames == None:\n",
    "                        break\n",
    "                    df.to_hdf(\n",
    "                        os.path.join(self.outdir, self.outfile),\n",
    "                        key=f'{self.outfile.split(\".\")[0]}',\n",
    "                        mode='a',\n",
    "                        format='table',\n",
    "                        append=True\n",
    "                    )\n",
    "\n",
    "    def __process__(self):\n",
    "        with tqdm(desc=f\"Mapping{self.empty_string:>18}\") as tqdmo:\n",
    "            def setter(x):\n",
    "              tqdmo.update(1)\n",
    "              return set(x.to_numpy())\n",
    "            groups = self.df.groupby(self.groupnames[0])[self.groupnames[1]].apply(setter)\n",
    "        array = groups.to_numpy()\n",
    "        names = names = list(groups.keys())\n",
    "        combinations = itertools.combinations(range(len(groups)), 2)\n",
    "        def compare(combination):\n",
    "            commons = array[combination[0]] & array[combination[1]]\n",
    "            return 1 if len(commons) >= 2 else 0, \", \".join([names[combination[0]], names[combination[1]]])\n",
    "        nck = int(ncr(array.shape[0], 2))\n",
    "        if self.save_association_cardinatily:\n",
    "            temp = np.memmap(\n",
    "                os.path.join(self.resultdir, 'temp.memmap'), \n",
    "                dtype='|U30', \n",
    "                mode='w+', \n",
    "                shape=(nck,2)\n",
    "            )\n",
    "        counter = 0\n",
    "        trueindex = 0\n",
    "        iterable = range(nck)\n",
    "        with tqdm(desc=f\"Reducing{self.empty_string:>18}\", iterable=iterable) as tqdmo:\n",
    "            for combination in combinations:\n",
    "                nck, commons = compare(combination)\n",
    "                counter += nck\n",
    "                if nck > 0 and self.save_association_cardinatily:\n",
    "                    temp[trueindex][0] = commons\n",
    "                    temp[trueindex][1] = str(nck)\n",
    "                    trueindex += 1\n",
    "                tqdmo.update(1)\n",
    "        if self.save_association_cardinatily:\n",
    "            results = np.memmap(\n",
    "                os.path.join(self.resultdir, self.resultfile), \n",
    "                dtype='|U30', \n",
    "                mode='w+', \n",
    "                shape=(trueindex, 2)\n",
    "            )\n",
    "            results[:] = temp[:trueindex]\n",
    "            os.remove(os.path.join(self.resultdir, 'temp.memmap'))\n",
    "        else:\n",
    "            results = None\n",
    "        return results, counter\n",
    "    def __call__(self):\n",
    "        try:\n",
    "            if not (os.path.exists(os.path.join(self.rawdir, self.rawfile))):\n",
    "                self.__download__()\n",
    "            if not (os.path.exists(os.path.join(self.outdir, self.outfile))):\n",
    "                self.__persist__()\n",
    "            self.df     = pd.read_hdf(\n",
    "                os.path.join(self.outdir, self.outfile),\n",
    "                key=f'{self.outfile.split(\".\")[0]}'\n",
    "            )\n",
    "            results, counter = self.__process__()\n",
    "            print(f\"No. Associations: {counter}\")\n",
    "        except KeyboardInterrupt:\n",
    "            for name in dir():\n",
    "                if not name.startswith('_'):\n",
    "                    del globals()[name]\n",
    "            print(\"Keyboard Interrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping                  : 33109it [00:06, 4928.75it/s] \n",
      "Reducing                  : 100%|ââââââââââ| 548086386/548086386 [42:57<00:00, 212615.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. Associations: 121114622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "big_targets = BigTargets(\n",
    "    './content/datasets',\n",
    "    'https://storage.googleapis.com/open-targets-data-releases/17.12/17.12_evidence_data.json.gz',\n",
    "    {\n",
    "        \"target\" : [\"target\", \"id\"],\n",
    "        \"disease\": [\"disease\", \"id\"],\n",
    "        \"score\":   [\"scores\", \"association_score\"]\n",
    "    }, \n",
    "    './content/results',\n",
    "    'tds.h5',\n",
    "    ['target', 'disease'],\n",
    "    './content/results',\n",
    "    'result.memmap'\n",
    ")\n",
    "big_targets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
